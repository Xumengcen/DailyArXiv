---
title: Latest 15 Papers - November 13, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Xumengcen/DailyArXiv) page for a better reading experience and more papers.**

## Composed Video Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[EgoCVR: An Egocentric Benchmark for Fine-Grained Composed Video Retrieval](https://arxiv.org/pdf/2407.16658v1)** | 2024-07-24 | ECCV 2024 |
| **[Composed Video Retrieval via Enriched Context and Discriminative Embeddings](https://arxiv.org/pdf/2403.16997v1)** | 2024-03-26 | CVPR-2024 |
| **[Beyond Simple Edits: Composed Video Retrieval with Dense Modifications](https://arxiv.org/pdf/2508.14039v1)** | 2025-08-20 | <details><summary>Accep...</summary><p>Accepted to ICCV-2025</p></details> |
| **[From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos](https://arxiv.org/pdf/2506.05274v1)** | 2025-06-06 |  |
| **[CoVR-2: Automatic Data Construction for Composed Video Retrieval](https://arxiv.org/pdf/2308.14746v4)** | 2025-04-02 | <details><summary>Appea...</summary><p>Appears in TPAMI 2024 (DOI: 10.1109/TPAMI.2024.3463799). Journal extension of the AAAI 2024 conference paper arXiv:2308.14746v3. Project page: https://imagine.enpc.fr/~ventural/covr/</p></details> |
| **[SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches](https://arxiv.org/pdf/2405.18334v3)** | 2024-07-02 |  |
| **[Tree-Augmented Cross-Modal Encoding for Complex-Query Video Retrieval](https://arxiv.org/pdf/2007.02503v1)** | 2020-07-07 | <details><summary>Accep...</summary><p>Accepted For 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2020)</p></details> |
| **[SoccerNet 2023 Challenges Results](https://arxiv.org/pdf/2309.06006v1)** | 2025-02-18 |  |
| **[Domain Adaptation in Multi-View Embedding for Cross-Modal Video Retrieval](https://arxiv.org/pdf/2110.12812v1)** | 2021-10-26 | 15 pages |
| **[Deep Learning for Video-Text Retrieval: a Review](https://arxiv.org/pdf/2302.12552v1)** | 2023-02-27 | <details><summary>Inter...</summary><p>International Journal of Multimedia Information Retrieval (IJMIR)</p></details> |
| **[Rekall: Specifying Video Events using Compositions of Spatiotemporal Labels](https://arxiv.org/pdf/1910.02993v1)** | 2019-10-09 |  |
| **[Bag of Genres for Video Retrieval](https://arxiv.org/pdf/1506.00051v2)** | 2020-12-29 |  |
| **[MovingFashion: a Benchmark for the Video-to-Shop Challenge](https://arxiv.org/pdf/2110.02627v4)** | 2021-10-15 | <details><summary>Accep...</summary><p>Accepted at WACV 2022</p></details> |
| **[APES: Audiovisual Person Search in Untrimmed Video](https://arxiv.org/pdf/2106.01667v1)** | 2021-06-04 |  |
| **[SoccerNet 2022 Challenges Results](https://arxiv.org/pdf/2210.02365v1)** | 2022-10-06 | <details><summary>Accep...</summary><p>Accepted at ACM MMSports 2022</p></details> |

## Composed Image Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Dual Relation Alignment for Composed Image Retrieval](https://arxiv.org/pdf/2309.02169v3)** | 2024-02-01 | <details><summary>The a...</summary><p>The architecture of our model changes, hence methodolgy and experiments changes a lot, We have significantly revised the original manuscript of the paper, so a withdraw of our original script is needed</p></details> |
| **[Benchmarking Robustness of Text-Image Composed Retrieval](https://arxiv.org/pdf/2311.14837v2)** | 2023-12-01 | <details><summary>Accep...</summary><p>Accepted by R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023</p></details> |
| **[Target-Guided Composed Image Retrieval](https://arxiv.org/pdf/2309.01366v1)** | 2023-09-06 |  |
| **[Zero-Shot Composed Image Retrieval with Textual Inversion](https://arxiv.org/pdf/2303.15247v2)** | 2023-08-22 | ICCV2023 |
| **[TMCIR: Token Merge Benefits Composed Image Retrieval](https://arxiv.org/pdf/2504.10995v1)** | 2025-04-16 | <details><summary>arXiv...</summary><p>arXiv admin note: text overlap with arXiv:2310.05473 by other authors</p></details> |
| **[Composed Image Retrieval for Remote Sensing](https://arxiv.org/pdf/2405.15587v3)** | 2024-07-30 | <details><summary>Accep...</summary><p>Accepted for ORAL presentation at the 2024 IEEE International Geoscience and Remote Sensing Symposium</p></details> |
| **[CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval](https://arxiv.org/pdf/2405.19149v2)** | 2024-05-31 | <details><summary>To ap...</summary><p>To appear at SIGIR 2024. arXiv admin note: text overlap with arXiv:2309.02169</p></details> |
| **[Composing Text and Image for Image Retrieval - An Empirical Odyssey](https://arxiv.org/pdf/1812.07119v1)** | 2018-12-19 |  |
| **[Training-free Zero-shot Composed Image Retrieval with Local Concept Reranking](https://arxiv.org/pdf/2312.08924v2)** | 2024-03-26 | Under Review |
| **[Composed Image Retrieval for Training-Free Domain Conversion](https://arxiv.org/pdf/2412.03297v1)** | 2024-12-05 | WACV 2025 |
| **[A Comprehensive Survey on Composed Image Retrieval](https://arxiv.org/pdf/2502.18495v2)** | 2025-03-05 |  |
| **[Sentence-level Prompts Benefit Composed Image Retrieval](https://arxiv.org/pdf/2310.05473v1)** | 2023-10-10 |  |
| **[Decompose Semantic Shifts for Composed Image Retrieval](https://arxiv.org/pdf/2309.09531v1)** | 2023-09-19 |  |
| **[Instance-Level Composed Image Retrieval](https://arxiv.org/pdf/2510.25387v1)** | 2025-10-30 | NeurIPS 2025 |
| **[NEUCORE: Neural Concept Reasoning for Composed Image Retrieval](https://arxiv.org/pdf/2310.01358v1)** | 2023-10-03 |  |

## Multimodal Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs](https://arxiv.org/pdf/2411.02571v2)** | 2025-02-25 | <details><summary>Accep...</summary><p>Accepted at ICLR 2025. We release the model weights at: https://huggingface.co/nvidia/MM-Embed</p></details> |
| **[A Survey of Multimodal Retrieval-Augmented Generation](https://arxiv.org/pdf/2504.08748v1)** | 2025-04-15 |  |
| **[A Survey of Multimodal Composite Editing and Retrieval](https://arxiv.org/pdf/2409.05405v2)** | 2024-09-12 | <details><summary>20 pa...</summary><p>20 pages, 3 figures, and 11 tables</p></details> |
| **[Mr. Right: Multimodal Retrieval on Representation of ImaGe witH Text](https://arxiv.org/pdf/2209.13764v1)** | 2022-09-29 | <details><summary>Datas...</summary><p>Dataset available at https://github.com/hsiehjackson/Mr.Right</p></details> |
| **[M3Retrieve: Benchmarking Multimodal Retrieval for Medicine](https://arxiv.org/pdf/2510.06888v1)** | 2025-10-09 | EMNLP Mains 2025 |
| **[Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/pdf/2506.22056v1)** | 2025-06-30 | <details><summary>18 pa...</summary><p>18 pages, 3 figures, accepted by Workshop on Computer-use Agents @ ICML 2025</p></details> |
| **[Self-adaptive Multimodal Retrieval-Augmented Generation](https://arxiv.org/pdf/2410.11321v1)** | 2024-10-16 |  |
| **[MMDocIR: Benchmarking Multimodal Retrieval for Long Documents](https://arxiv.org/pdf/2501.08828v3)** | 2025-11-10 | <details><summary>Paper...</summary><p>Paper accepted to EMNLP-2025(Main)</p></details> |
| **[Multimodal semantic retrieval for product search](https://arxiv.org/pdf/2501.07365v3)** | 2025-02-18 | <details><summary>Accep...</summary><p>Accepted at EReL@MIR WWW 2025</p></details> |
| **[Retrieval-Augmented Multimodal Language Modeling](https://arxiv.org/pdf/2211.12561v2)** | 2023-06-07 | <details><summary>Publi...</summary><p>Published at ICML 2023. Blog post available at https://cs.stanford.edu/~myasu/blog/racm3/</p></details> |
| **[Probabilistic Compositional Embeddings for Multimodal Image Retrieval](https://arxiv.org/pdf/2204.05845v1)** | 2022-04-13 | <details><summary>CVPR2...</summary><p>CVPR2022 MULA workshop</p></details> |
| **[UniIR: Training and Benchmarking Universal Multimodal Information Retrievers](https://arxiv.org/pdf/2311.17136v1)** | 2023-11-30 | <details><summary>Our c...</summary><p>Our code and dataset are available on this project page: https://tiger-ai-lab.github.io/UniIR/</p></details> |
| **[MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering](https://arxiv.org/pdf/2408.08521v2)** | 2025-02-10 | <details><summary>Accep...</summary><p>Accepted at COLING 2025</p></details> |
| **[Progressive Multimodal Reasoning via Active Retrieval](https://arxiv.org/pdf/2412.14835v1)** | 2024-12-20 | Working in progress |
| **[Generalized Contrastive Learning for Universal Multimodal Retrieval](https://arxiv.org/pdf/2509.25638v1)** | 2025-10-01 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |

