---
title: Latest 15 Papers - November 19, 2025
labels: documentation
---
**Please check the [Github](https://github.com/Xumengcen/DailyArXiv) page for a better reading experience and more papers.**

## Composed Video Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Beyond Simple Edits: Composed Video Retrieval with Dense Modifications](https://arxiv.org/abs/2508.14039v1)** | 2025-08-19 | <details><summary>Accep...</summary><p>Accepted to ICCV-2025</p></details> |
| **[Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment](https://arxiv.org/abs/2506.21903v2)** | 2025-08-16 | <details><summary>This ...</summary><p>This is an extended version of a paper accepted to MIPR 2025</p></details> |
| **[U-MARVEL: Unveiling Key Factors for Universal Multimodal Retrieval via Embedding Learning with MLLMs](https://arxiv.org/abs/2507.14902v1)** | 2025-07-20 | <details><summary>Techn...</summary><p>Technical Report (in progress)</p></details> |
| **[Composed Multi-modal Retrieval: A Survey of Approaches and Applications](https://arxiv.org/abs/2503.01334v2)** | 2025-07-19 |  |
| **[VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning](https://arxiv.org/abs/2506.06097v1)** | 2025-06-06 |  |
| **[From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos](https://arxiv.org/abs/2506.05274v1)** | 2025-06-05 |  |
| **[One-Shot Imitation under Mismatched Execution](https://arxiv.org/abs/2409.06615v6)** | 2025-03-28 |  |
| **[Stitch-a-Recipe: Video Demonstration from Multistep Descriptions](https://arxiv.org/abs/2503.13821v1)** | 2025-03-18 |  |
| **[Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding](https://arxiv.org/abs/2503.12663v1)** | 2025-03-16 |  |
| **[CRM: Retrieval Model with Controllable Condition](https://arxiv.org/abs/2412.13844v1)** | 2024-12-18 |  |
| **[Agent-based Video Trimming](https://arxiv.org/abs/2412.09513v1)** | 2024-12-12 |  |
| **[CoVR-2: Automatic Data Construction for Composed Video Retrieval](https://arxiv.org/abs/2308.14746v4)** | 2024-11-05 | <details><summary>Appea...</summary><p>Appears in TPAMI 2024 (DOI: 10.1109/TPAMI.2024.3463799). Journal extension of the AAAI 2024 conference paper arXiv:2308.14746v3. Project page: https://imagine.enpc.fr/~ventural/covr/</p></details> |
| **[EgoCVR: An Egocentric Benchmark for Fine-Grained Composed Video Retrieval](https://arxiv.org/abs/2407.16658v1)** | 2024-07-23 | ECCV 2024 |
| **[SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches](https://arxiv.org/abs/2405.18334v3)** | 2024-07-01 |  |
| **[Composed Video Retrieval via Enriched Context and Discriminative Embeddings](https://arxiv.org/abs/2403.16997v1)** | 2024-03-25 | CVPR-2024 |

## Composed Image Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval](https://arxiv.org/abs/2511.05020v1)** | 2025-11-07 | 10 pages,4 figures |
| **[MLLM-Driven Semantic Identifier Generation for Generative Cross-Modal Retrieval](https://arxiv.org/abs/2509.17359v2)** | 2025-11-03 | <details><summary>We pl...</summary><p>We plan to revise the methodology and update the experimental analysis before resubmission</p></details> |
| **[Instance-Level Composed Image Retrieval](https://arxiv.org/abs/2510.25387v1)** | 2025-10-29 | NeurIPS 2025 |
| **[MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543v1)** | 2025-10-17 |  |
| **[Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval](https://arxiv.org/abs/2507.05970v3)** | 2025-10-13 | <details><summary>This ...</summary><p>This paper was originally submitted to ACM MM 2025 on April 12, 2025</p></details> |
| **[CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.08003v1)** | 2025-10-09 |  |
| **[Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces](https://arxiv.org/abs/2510.05071v1)** | 2025-10-06 |  |
| **[SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2509.26330v1)** | 2025-09-30 | 20 pages, 9 figures |
| **[SETR: A Two-Stage Semantic-Enhanced Framework for Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2509.26012v1)** | 2025-09-30 |  |
| **[Generalized Contrastive Learning for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.25638v1)** | 2025-09-30 | <details><summary>Accep...</summary><p>Accepted to NeurIPS 2025</p></details> |
| **[TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models](https://arxiv.org/abs/2509.25143v1)** | 2025-09-29 |  |
| **[Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation](https://arxiv.org/abs/2509.22307v1)** | 2025-09-26 |  |
| **[PDV: Prompt Directional Vectors for Zero-shot Composed Image Retrieval](https://arxiv.org/abs/2502.07215v3)** | 2025-09-26 |  |
| **[Chain-of-Thought Re-ranking for Image Retrieval Tasks](https://arxiv.org/abs/2509.14746v1)** | 2025-09-18 |  |
| **[Recurrence Meets Transformers for Universal Multimodal Retrieval](https://arxiv.org/abs/2509.08897v1)** | 2025-09-10 |  |

## Multimodal Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions](https://arxiv.org/abs/2508.05430v2)** | 2025-11-18 | <details><summary>NeurI...</summary><p>NeurIPS 2025. Code: https://github.com/hbaniecki/fixlip</p></details> |
| **[Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249v1)** | 2025-11-18 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229v1)** | 2025-11-18 |  |
| **[GAIS: Frame-Level Gated Audio-Visual Integration with Semantic Variance-Scaled Perturbation for Text-Video Retrieval](https://arxiv.org/abs/2508.01711v2)** | 2025-11-18 | 13 pages |
| **[CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670v3)** | 2025-11-18 | 19 pages,8 figures |
| **[SMART: Shot-Aware Multimodal Video Moment Retrieval with Audio-Enhanced MLLM](https://arxiv.org/abs/2511.14143v1)** | 2025-11-18 |  |
| **[HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027v1)** | 2025-11-18 |  |
| **[Attention Grounded Enhancement for Visual Document Retrieval](https://arxiv.org/abs/2511.13415v1)** | 2025-11-17 |  |
| **[MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications](https://arxiv.org/abs/2511.13131v1)** | 2025-11-17 |  |
| **[uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036v1)** | 2025-11-17 | <details><summary>Our p...</summary><p>Our project page can be found at https://dinyudin203.github.io/uCLIP-project/</p></details> |
| **[WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](https://arxiv.org/abs/2511.12997v1)** | 2025-11-17 | <details><summary>18 pa...</summary><p>18 pages; work in progress</p></details> |
| **[On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869v1)** | 2025-11-17 | <details><summary>Submi...</summary><p>Submitted to TMLR 2025</p></details> |
| **[MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns](https://arxiv.org/abs/2511.10390v2)** | 2025-11-16 |  |
| **[History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754v2)** | 2025-11-16 | <details><summary>Accep...</summary><p>Accepted in IEEE BigData 2025</p></details> |
| **[Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework](https://arxiv.org/abs/2506.02454v2)** | 2025-11-16 | AAAI 2026 Oral |

